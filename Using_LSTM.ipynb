{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  ** Yin, Z., & Zhang, J. (2023). LSTM-based EEG emotion recognition. Biomedical Signal Processing and Control, 81, 104479. **\n",
        "*  ** Li, X., Song, D., Zhang, P., et al. (2021). IEEE Access, 9, 69276-69286. **"
      ],
      "metadata": {
        "id": "G7Ur8d61csi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e1Pi8EAbjv8",
        "outputId": "121e5125-523b-4dda-88b0-68e213dcc5ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CseTkuAAbgxv",
        "outputId": "f63712fe-ca47-4d80-8b48-8b086b91b8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LSTM (EEG) Valence ---\n",
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - accuracy: 0.1066 - loss: 2.6646 - val_accuracy: 0.1809 - val_loss: 2.2980\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1943 - loss: 2.2225 - val_accuracy: 0.1809 - val_loss: 2.2946\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2397 - loss: 2.1486 - val_accuracy: 0.1489 - val_loss: 2.2911\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2672 - loss: 2.0476 - val_accuracy: 0.1915 - val_loss: 2.2875\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3251 - loss: 1.8947 - val_accuracy: 0.2021 - val_loss: 2.2845\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2699 - loss: 1.9104 - val_accuracy: 0.1915 - val_loss: 2.2823\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3164 - loss: 1.9007 - val_accuracy: 0.1596 - val_loss: 2.2803\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.3210 - loss: 1.7841 - val_accuracy: 0.1383 - val_loss: 2.2782\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.3169 - loss: 1.8454 - val_accuracy: 0.1596 - val_loss: 2.2754\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3716 - loss: 1.7314 - val_accuracy: 0.1596 - val_loss: 2.2735\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.3892 - loss: 1.6990 - val_accuracy: 0.1596 - val_loss: 2.2716\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4185 - loss: 1.6670 - val_accuracy: 0.1383 - val_loss: 2.2696\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4029 - loss: 1.6419 - val_accuracy: 0.1383 - val_loss: 2.2684\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4585 - loss: 1.5768 - val_accuracy: 0.1489 - val_loss: 2.2660\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4528 - loss: 1.5595 - val_accuracy: 0.1489 - val_loss: 2.2632\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4937 - loss: 1.5036 - val_accuracy: 0.1383 - val_loss: 2.2610\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4670 - loss: 1.5204 - val_accuracy: 0.1383 - val_loss: 2.2582\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4914 - loss: 1.4745 - val_accuracy: 0.1489 - val_loss: 2.2547\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4875 - loss: 1.4847 - val_accuracy: 0.1383 - val_loss: 2.2499\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5385 - loss: 1.3652 - val_accuracy: 0.1383 - val_loss: 2.2442\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5240 - loss: 1.3830 - val_accuracy: 0.1596 - val_loss: 2.2401\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5129 - loss: 1.4087 - val_accuracy: 0.1383 - val_loss: 2.2375\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5618 - loss: 1.3498 - val_accuracy: 0.1596 - val_loss: 2.2347\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5759 - loss: 1.2839 - val_accuracy: 0.1383 - val_loss: 2.2309\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5697 - loss: 1.2627 - val_accuracy: 0.1383 - val_loss: 2.2254\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5954 - loss: 1.2384 - val_accuracy: 0.2128 - val_loss: 2.2185\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6012 - loss: 1.1780 - val_accuracy: 0.2021 - val_loss: 2.2089\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5801 - loss: 1.2057 - val_accuracy: 0.2021 - val_loss: 2.2022\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.6389 - loss: 1.1163 - val_accuracy: 0.2021 - val_loss: 2.1929\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5933 - loss: 1.1876 - val_accuracy: 0.2766 - val_loss: 2.1854\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6750 - loss: 1.0403 - val_accuracy: 0.2340 - val_loss: 2.1796\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.6548 - loss: 1.0737 - val_accuracy: 0.2340 - val_loss: 2.1738\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6801 - loss: 1.0403 - val_accuracy: 0.2234 - val_loss: 2.1665\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6700 - loss: 0.9718 - val_accuracy: 0.2447 - val_loss: 2.1555\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6899 - loss: 0.9483 - val_accuracy: 0.2340 - val_loss: 2.1534\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7323 - loss: 0.8858 - val_accuracy: 0.2340 - val_loss: 2.1406\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7177 - loss: 0.9238 - val_accuracy: 0.2340 - val_loss: 2.1366\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6954 - loss: 0.9335 - val_accuracy: 0.2553 - val_loss: 2.1165\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7263 - loss: 0.8880 - val_accuracy: 0.2979 - val_loss: 2.1153\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7050 - loss: 0.8655 - val_accuracy: 0.3085 - val_loss: 2.1137\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7716 - loss: 0.8002 - val_accuracy: 0.3298 - val_loss: 2.0953\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7426 - loss: 0.8164 - val_accuracy: 0.2979 - val_loss: 2.0844\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7289 - loss: 0.8171 - val_accuracy: 0.2447 - val_loss: 2.1232\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7123 - loss: 0.8410 - val_accuracy: 0.3085 - val_loss: 2.1001\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7935 - loss: 0.7490 - val_accuracy: 0.3298 - val_loss: 2.0653\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7575 - loss: 0.7696 - val_accuracy: 0.3936 - val_loss: 2.0311\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7725 - loss: 0.7292 - val_accuracy: 0.3723 - val_loss: 2.0245\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7792 - loss: 0.6892 - val_accuracy: 0.3617 - val_loss: 2.0071\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7965 - loss: 0.6022 - val_accuracy: 0.3298 - val_loss: 2.0114\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7790 - loss: 0.6790 - val_accuracy: 0.3511 - val_loss: 2.0192\n",
            "LSTM (EEG) Valence Accuracy: 35.11%\n",
            "--- LSTM (EEG) Arousal ---\n",
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 332ms/step - accuracy: 0.0970 - loss: 2.7423 - val_accuracy: 0.1064 - val_loss: 2.3008\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.1476 - loss: 2.4162 - val_accuracy: 0.1489 - val_loss: 2.2984\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2621 - loss: 2.1703 - val_accuracy: 0.2447 - val_loss: 2.2962\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2525 - loss: 2.0913 - val_accuracy: 0.2234 - val_loss: 2.2935\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2848 - loss: 2.0554 - val_accuracy: 0.2128 - val_loss: 2.2905\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.3332 - loss: 1.9090 - val_accuracy: 0.2340 - val_loss: 2.2879\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.3784 - loss: 1.8343 - val_accuracy: 0.1915 - val_loss: 2.2854\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.3849 - loss: 1.8310 - val_accuracy: 0.1915 - val_loss: 2.2831\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.4018 - loss: 1.7809 - val_accuracy: 0.1915 - val_loss: 2.2810\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3800 - loss: 1.7901 - val_accuracy: 0.1489 - val_loss: 2.2794\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.4056 - loss: 1.7361 - val_accuracy: 0.2021 - val_loss: 2.2778\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.4004 - loss: 1.6929 - val_accuracy: 0.2128 - val_loss: 2.2757\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.3951 - loss: 1.7088 - val_accuracy: 0.2660 - val_loss: 2.2726\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4330 - loss: 1.6552 - val_accuracy: 0.2234 - val_loss: 2.2699\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4624 - loss: 1.6188 - val_accuracy: 0.2234 - val_loss: 2.2677\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4736 - loss: 1.5786 - val_accuracy: 0.2234 - val_loss: 2.2665\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4869 - loss: 1.5229 - val_accuracy: 0.2234 - val_loss: 2.2646\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4626 - loss: 1.5496 - val_accuracy: 0.2234 - val_loss: 2.2633\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5111 - loss: 1.4302 - val_accuracy: 0.1915 - val_loss: 2.2610\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5035 - loss: 1.4607 - val_accuracy: 0.1809 - val_loss: 2.2579\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5346 - loss: 1.4701 - val_accuracy: 0.1702 - val_loss: 2.2560\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5382 - loss: 1.3703 - val_accuracy: 0.1702 - val_loss: 2.2525\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5727 - loss: 1.3459 - val_accuracy: 0.1702 - val_loss: 2.2510\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5619 - loss: 1.3076 - val_accuracy: 0.1915 - val_loss: 2.2492\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5727 - loss: 1.2817 - val_accuracy: 0.1809 - val_loss: 2.2421\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5952 - loss: 1.2596 - val_accuracy: 0.2021 - val_loss: 2.2356\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5820 - loss: 1.2522 - val_accuracy: 0.2340 - val_loss: 2.2333\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5906 - loss: 1.2235 - val_accuracy: 0.2234 - val_loss: 2.2327\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6487 - loss: 1.1815 - val_accuracy: 0.2234 - val_loss: 2.2289\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6235 - loss: 1.1792 - val_accuracy: 0.1809 - val_loss: 2.2215\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6240 - loss: 1.1248 - val_accuracy: 0.2234 - val_loss: 2.2136\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6360 - loss: 1.0965 - val_accuracy: 0.2340 - val_loss: 2.2090\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6543 - loss: 1.1155 - val_accuracy: 0.2340 - val_loss: 2.1994\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6514 - loss: 1.0500 - val_accuracy: 0.2447 - val_loss: 2.2012\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6306 - loss: 1.0858 - val_accuracy: 0.2447 - val_loss: 2.2000\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6560 - loss: 1.0126 - val_accuracy: 0.2234 - val_loss: 2.1783\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6843 - loss: 0.9628 - val_accuracy: 0.2340 - val_loss: 2.1888\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6567 - loss: 0.9765 - val_accuracy: 0.2340 - val_loss: 2.1687\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6954 - loss: 0.9793 - val_accuracy: 0.2660 - val_loss: 2.1506\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7127 - loss: 0.9496 - val_accuracy: 0.3085 - val_loss: 2.1471\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6725 - loss: 0.9301 - val_accuracy: 0.2660 - val_loss: 2.1363\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7194 - loss: 0.8755 - val_accuracy: 0.2660 - val_loss: 2.1143\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7306 - loss: 0.8679 - val_accuracy: 0.2553 - val_loss: 2.1053\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7122 - loss: 0.8582 - val_accuracy: 0.2447 - val_loss: 2.1138\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7188 - loss: 0.8385 - val_accuracy: 0.2553 - val_loss: 2.1173\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7277 - loss: 0.8029 - val_accuracy: 0.2766 - val_loss: 2.0699\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7481 - loss: 0.8247 - val_accuracy: 0.2979 - val_loss: 2.0690\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7963 - loss: 0.7185 - val_accuracy: 0.2553 - val_loss: 2.0538\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7475 - loss: 0.7693 - val_accuracy: 0.2340 - val_loss: 2.0384\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8031 - loss: 0.6631 - val_accuracy: 0.3085 - val_loss: 2.0430\n",
            "LSTM (EEG) Arousal Accuracy: 30.85%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Input\n",
        "\n",
        "# === 1. LOAD DATA ===\n",
        "data_path = '/content/drive/MyDrive/dataset/preprocessed-data/mahnob_HCI_preprocessed_all.npy'\n",
        "data = np.load(data_path, allow_pickle=True)\n",
        "X_eeg = np.array([entry['eeg_data'] for entry in data])     # [samples, 5, 512]\n",
        "y = np.array([entry['labels'] for entry in data])           # [samples, ...]\n",
        "\n",
        "# === 2. (OPTIONAL) BALANCE CLASSES: for fair results\n",
        "def balance_classes(X, y, label_idx):\n",
        "    labels = y[:, label_idx]\n",
        "    classes, counts = np.unique(labels, return_counts=True)\n",
        "    max_count = np.max(counts)\n",
        "    Xb, yb = [], []\n",
        "    for c in classes:\n",
        "        idxs = np.where(labels == c)[0]\n",
        "        Xc = X[idxs]\n",
        "        yc = y[idxs]\n",
        "        if len(Xc) < max_count:\n",
        "            X_over, y_over = resample(Xc, yc, replace=True, n_samples=max_count-len(Xc), random_state=42)\n",
        "            Xc = np.concatenate([Xc, X_over])\n",
        "            yc = np.concatenate([yc, y_over])\n",
        "        Xb.append(Xc)\n",
        "        yb.append(yc)\n",
        "    return np.concatenate(Xb), np.concatenate(yb)\n",
        "\n",
        "# (You may balance for both valence [idx=1] and then arousal [idx=2], or just one)\n",
        "X_eeg_bal, y_bal = balance_classes(X_eeg, y, label_idx=1)  # Valence\n",
        "X_eeg_bal, y_bal = balance_classes(X_eeg_bal, y_bal, label_idx=2)  # Then Arousal if you want\n",
        "\n",
        "# === 3. PREPARE INPUT FOR LSTM ===\n",
        "# Keras LSTM expects: [samples, time_steps, features]\n",
        "# Let's feed each sample as 512 time steps, 5 features (channels)\n",
        "X_lstm = np.transpose(X_eeg_bal, (0, 2, 1))  # [samples, 512, 5]\n",
        "\n",
        "# Choose label: valence or arousal\n",
        "y_valence = y_bal[:, 1]\n",
        "y_arousal = y_bal[:, 2]\n",
        "num_valence = int(np.max(y_valence)) + 1\n",
        "num_arousal = int(np.max(y_arousal)) + 1\n",
        "yv_cat = to_categorical(y_valence, num_classes=num_valence)\n",
        "ya_cat = to_categorical(y_arousal, num_classes=num_arousal)\n",
        "\n",
        "# === 4. SPLIT FOR VALENCE & AROUSAL ===\n",
        "X_tr, X_te, yv_tr, yv_te, ya_tr, ya_te = train_test_split(X_lstm, yv_cat, ya_cat, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 5. LSTM-ONLY MODEL: STATE OF THE ART FOR EMOTION (e.g., Yin et al., Biomed Signal Process Control, 2023) ===\n",
        "def build_lstm(num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(512, 5)),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_lstm_val = build_lstm(num_valence)\n",
        "model_lstm_aro = build_lstm(num_arousal)\n",
        "\n",
        "# === 6. TRAIN & EVALUATE: VALENCE ===\n",
        "print('--- LSTM (EEG) Valence ---')\n",
        "history_val = model_lstm_val.fit(\n",
        "    X_tr, yv_tr,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_te, yv_te)\n",
        ")\n",
        "loss_val, acc_val = model_lstm_val.evaluate(X_te, yv_te, verbose=0)\n",
        "print(f\"LSTM (EEG) Valence Accuracy: {acc_val*100:.2f}%\")\n",
        "\n",
        "# === 7. TRAIN & EVALUATE: AROUSAL ===\n",
        "print('--- LSTM (EEG) Arousal ---')\n",
        "history_aro = model_lstm_aro.fit(\n",
        "    X_tr, ya_tr,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_te, ya_te)\n",
        ")\n",
        "loss_aro, acc_aro = model_lstm_aro.evaluate(X_te, ya_te, verbose=0)\n",
        "print(f\"LSTM (EEG) Arousal Accuracy: {acc_aro*100:.2f}%\")\n"
      ]
    }
  ]
}